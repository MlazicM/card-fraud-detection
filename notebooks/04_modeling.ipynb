{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e7686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56651\n",
      "           1       0.05      0.87      0.10        95\n",
      "\n",
      "    accuracy                           0.97     56746\n",
      "   macro avg       0.53      0.92      0.54     56746\n",
      "weighted avg       1.00      0.97      0.98     56746\n",
      "\n",
      "[[55094  1557]\n",
      " [   12    83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.94      0.79      0.86        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.97      0.89      0.93     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56646     5]\n",
      " [   20    75]]\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9724\n",
      "Precision: 0.0506\n",
      "Recall: 0.8737\n",
      "F1 Score: 0.0957\n",
      "\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.9996\n",
      "Precision: 0.9375\n",
      "Recall: 0.7895\n",
      "F1 Score: 0.8571\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.75      0.80      0.77        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.87      0.90      0.89     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56625    26]\n",
      " [   19    76]]\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.9992\n",
      "Precision: 0.7451\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7716\n",
      "\n",
      "\n",
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.9724\n",
      "Precision: 0.0506\n",
      "Recall: 0.8737\n",
      "F1 Score: 0.0957\n",
      "\n",
      "\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.9996\n",
      "Precision: 0.9375\n",
      "Recall: 0.7895\n",
      "F1 Score: 0.8571\n",
      "\n",
      "\n",
      "XGBoost Metrics:\n",
      "Accuracy: 0.9992\n",
      "Precision: 0.7451\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7716\n",
      "\n",
      "\n",
      "Compering this three models, the best one is XGBoost with the highest accuracy, precision, recall and F1 score. Random Forest also performed well, while Logistic Regression had the lowest performance among the three models.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train_smote = pd.read_csv('../data/processed/X_train_smote.csv')\n",
    "y_train_smote = pd.read_csv('../data/processed/y_train_smote.csv').values.ravel()\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.ravel()\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#Adding RandomForest and comparing the results\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "#Compering the results of Logistic Regression and Random Forest\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def print_metrics(y_true, y_pred, model_name):\n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_true, y_pred):.4f}\")\n",
    "    print(\"\\n\")\n",
    "print_metrics(y_test, y_pred, \"Logistic Regression\")\n",
    "print_metrics(y_test, y_pred_rf, \"Random Forest\") \n",
    "#Adding XGBoost and comparing the results\n",
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train_smote, y_train_smote)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "print_metrics(y_test, y_pred_xgb, \"XGBoost\")\n",
    "#Comparing the results of all three models\n",
    "print_metrics(y_test, y_pred, \"Logistic Regression\")\n",
    "print_metrics(y_test, y_pred_rf, \"Random Forest\")\n",
    "print_metrics(y_test, y_pred_xgb, \"XGBoost\")\n",
    "print(f\"Compering this three models, the best one is XGBoost with the highest accuracy, precision, recall and F1 score. Random Forest also performed well, while Logistic Regression had the lowest performance among the three models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
