{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b50ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         hour_of_day     time_delta  velocity_300s  amount_zscore\n",
      "count  453204.000000  453204.000000  453204.000000  453204.000000\n",
      "mean       -0.160424       0.173606      -0.236946      -0.118799\n",
      "std         1.028043       1.190593       1.174422       1.106499\n",
      "min        -2.411161      -0.578526      -3.465152      -1.906478\n",
      "25%        -0.867125      -0.578526      -0.650620      -1.245164\n",
      "50%        -0.022355      -0.138705       0.216683      -0.143782\n",
      "75%         0.676910       0.371798       0.492112       0.829928\n",
      "max         1.534708      29.831852       4.381245       4.062703\n",
      "Train: (453204, 33), Test: (56746, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Load raw dataset\n",
    "df = pd.read_csv(\"../data/raw/creditcard.csv\")\n",
    "\n",
    "# Remove duplicate rows to avoid data leakage\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort by Time to ensure chronological order — required for time-based features\n",
    "df.sort_values(by='Time', inplace=True)\n",
    "\n",
    "# Extract hour of day from Time (seconds since first transaction)\n",
    "df['hour_of_day'] = (df['Time'] // 3600) % 24\n",
    "\n",
    "# Time delta: seconds between consecutive transactions\n",
    "# First transaction has no previous — fill with 0\n",
    "df['time_delta'] = df['Time'].diff().fillna(0)\n",
    "\n",
    "# Log-transform Amount to reduce skewness and outlier impact\n",
    "df['Amount'] = np.log1p(df['Amount'])\n",
    "\n",
    "# Transaction velocity: number of transactions in the last 300 seconds\n",
    "# High velocity is a strong fraud signal — thieves act fast\n",
    "time_index = pd.to_datetime(df['Time'], unit='s')\n",
    "df['velocity_300s'] = (\n",
    "    df['Amount']\n",
    "    .set_axis(time_index)\n",
    "    .rolling('300s')\n",
    "    .count()\n",
    "    .values\n",
    ")\n",
    "\n",
    "# Drop Time — no longer needed, all time-based features are extracted\n",
    "df.drop(columns=['Time'], inplace=True)\n",
    "# Sanity check — verify time-based features look reasonable\n",
    "print(df['time_delta'].min())\n",
    "print(df[df['time_delta'] < 0].shape)\n",
    "# Train/test split — stratified to preserve class imbalance ratio\n",
    "# Split must happen before any statistics are computed to avoid data leakage\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Z-score of Amount — computed only on train statistics\n",
    "# Applying train mean/std to test set prevents data leakage\n",
    "mean_amount = X_train['Amount'].mean()\n",
    "std_amount = X_train['Amount'].std()\n",
    "X_train['amount_zscore'] = (X_train['Amount'] - mean_amount) / std_amount\n",
    "X_test['amount_zscore'] = (X_test['Amount'] - mean_amount) / std_amount\n",
    "\n",
    "# StandardScaler — fit only on train, then transform both sets\n",
    "# Prevents test set statistics from influencing the scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame — scaler returns numpy array\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "# SMOTE applied only on train set to handle class imbalance\n",
    "# Never apply SMOTE on test set — that would be data leakage\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Sanity check — verify feature values look reasonable\n",
    "print(X_train_smote[['hour_of_day', 'time_delta', 'velocity_300s', 'amount_zscore']].describe())\n",
    "\n",
    "# Save processed data and scaler for future use\n",
    "X_train_smote.to_csv('../data/processed/X_train_smote.csv', index=False)\n",
    "y_train_smote.to_csv('../data/processed/y_train_smote.csv', index=False)\n",
    "X_test_scaled.to_csv('../data/processed/X_test.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "\n",
    "print(f\"Train: {X_train_smote.shape}, Test: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d2d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
